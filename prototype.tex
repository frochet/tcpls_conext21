% !TEX root = ./paper.tex
\label{sec:content}

In this section, we describe our \tcpls implementation. In a nutshell, it provides the following benefits.
($i$) Applications can use parallel streams and multiplex them over \tcp connections with different cryptographic contexts.
($ii$) An experimental API that wraps \tls and \tcp and enables applications to
    handle multihoming, multipathing, and various transport layer mechanisms.
($iii$) An improved \tcp extensibility mechanism that sends \tcp options
   through the secure \tcpls channel (as described in
   Sec.~\ref{sec:background-design}). We currently support Linux's \tcp User Timeout option. Supporting another \tcp option is only a matter of extending the sender's API and processing the option on the receiver side. \tcpls's internal machinery can already send any \tcp option during (server-side) or after (client-side) the \tcp handshake.
($iv$) Different multipath modes for the \tcpls streams: bandwidth aggregation
or independent paths.
($v$) The ability for the server to send eBPF bytecode over the secure channel to upgrade the client's \tcp congestion control scheme or tune other \tcp mechanisms~\cite{brakmo2017tcp,tran2019beyond}. Variable-length options (e.g., eBPF bytecode) can be sent within streams to take advantage of bandwidth aggregation or Failover if those features are enabled.
($vi$) Different connection migration modes: Failover and Application-level
Connection Migration.


%\fr{I don't want to give the impression that everything works like a charm -- I
%would need 1 more year to have something production ready}
%We stress that all of these features have been tested but this prototype is a
%research-level implementation. The implementation can
%showcase those features but is however not yet ready for production, as many
%bugs likely remain despite our unit tests and integration tests. Portability was
%neither part of our goals, but might be necessary for a production ready \tcpls
%library.

\subsection{The \tcpls API}

The API that applications use to interact with a protocol plays an important
role in leveraging all the protocol features. The most popular
API to interact with the transport layer remains the BSD socket API. Researchers
and the IETF have explored new ways to expose a transport
API~\cite{draft-ietf-taps-arch,hruby2014sockets,rfc6458,schmidt2013socket}.
Due to space limitations, we provide in appendix~\ref{appendix:api} a simple example of our API workflow,
which builds upon good practices proposed by the outlined research.

%In this spirit, application-level developers would only be required to
%configure a \tcpls context and register function callbacks.
%We design \tcpls such
%that the application-level developers can ignore any notion of Network IPC as
%defined by, for example, the POSIX API, the Berkeley socket API or Winsock,
%facilitating application-level development by offering a more concrete
%session-level interface based on asynchronous network events.
%The overall idea is to offer to application developers the opportunity to tune
%the transport protocol for a better usage of the network from their own
%application protocol, which might depend on its distinguishing
%features.
%\todo{we need to explain the mpjoin}


%Note, those features are not stable yet, and many bugs remain to be fixed.

\subsection{Multipathing}

\subsubsection{Data Aggregation}
The application can create and join several \tcp connections to
the same \tcpls session. As soon as one of the peers attaches streams to
different \tcp connections of the session, and enables the aggregation mode,
\tcpls adds a sequence number encrypted in the \tls record payload. This
sequence number is used to reorder the received records after decryption. Our
current implementation supports one global ordering, but
we envision for the \tcpls protocol to have streams potentially detached from
the global orderings. For example, a HTTP application may want to use an
aggregation mode for 2 streams over 2 \tcp connections downloading a video
content for the video playback engine, but the other streams used by the HTTP
client do not necessarily need to be part of the multipath bandwidth aggregation.
Such a feature may be implemented through a negotiation of the aggregation
mode.

Our implementation currently includes a round-robin scheduler. We expect to
support other schedulers in the future and allow the application to select its preferred scheduler through the API, or even send it as eBPF bytecode over the session. The more \tcpls receives records in order, the more it can deliver them in a zero-copy fashion to the application. When a record is received out-of-sequence, its content is copied in a reordering buffer. The performance of our multipath bandwidth aggregation is evaluated in Sec.~\ref{sec:bwaggr}

\subsubsection{Failover}\label{failover}
Failover is a binary mode (on/off) that is fully internal to \tcpls.
Once activated, \tcpls exchanges acknowledgments for records received on each stream. These acknowldgments are stream-based and configurable. The default acknowledgment policy is to acknowledge every 16 received records, or when a stream has processed more than $249,600$ bytes since the last acknowledgment. When a \tcp connection sustaining \tcpls streams suffers from a network outage (e.g., a \rst is received or the connection becomes idle for too long), we move the stream to a new \tcp connection, retransmit the unacked records, and resume the transfer. Our prototype handles failover over IPv4 and IPv6 \tcp connections, and by default, chooses different source and destination addresses than the failed \tcp connection if some are available.
%Failover might be negotiated by both party, or
%enabled by default by both party.
Depending on the application type, Failover might be enabled or not by default. It is also possible to activate Failover during a \tcpls session by sending a message on the secure channel. We evaluate the performance of Failover in Sec.~\ref{sec:eval_failover}

%\subsubsection{Application-level Connection Migration}
%\label{sec:connmigr}


%When an application feels right to migrate its connection, it
%can follow those simple steps: activating the multipath aggregation
%mode, then making a \tcpls join handshake on the new path. Then, opening a new stream
%and attaching it to the new \tcp connection, and closing the initial
%stream would make the data transfert enter in a temporary two-paths aggregated mode in
%which the other peer's first path flushes its data if any, and then gracefully close the \tcp
%connection achieving a smooth migration. In practice, such a migration would
%achieve better goodput than a QUIC single-path migration design in which the
%data path is temporally broken and then recovered. In our design, the
%application can make such a migration in 5 API calls.

%\subsection{TCP Options and Kernel extensibility}

\subsection{\tcpls Session Establishment}

One notable feature of \quic is its ability to establish a secure connection within one round-trip-time with a new server. For subsequent connections with the same server, \quic can even include data during the handshake.

\tls 1.3 also includes a fast handshake for subsequent connections. When used with \tcp Fast Open (TFO)~\cite{radhakrishnan2011tcp}, the \tls handshake can be sent together with \tcp's three way handshake. However, TFO suffers from privacy issues~\cite{sy2020enhanced}. For this reason, we did not enable it by default in \tcpls. We could revise this decision if a solution similar to \tcp
FOP~\cite{sy2020enhanced} is included in mainline TCP implementations.


%One argument for QUIC's usage on the web was its first 1-rtt secure connection.
%Compared to TLS/TCP, QUIC has only one handshake and can then proceed with the
%application data. $TLS/TCP$ has two: First, the \tcp three-way handshake, and
%then the \tls handshake.

%\tcpls can use \tcp's TFO~\cite{radhakrishnan2011tcp}
%and send the \texttt{ClientHello} message within the \tcp SYN's payload,
%achieving the same roundtrips than QUIC. However, TFO suffers from privacy
%issues~\cite{sy2020enhanced}, thus we did not enable it by default. In the
%future, we may expect to revise our choice if a solution similar to \tcp
%FOP~\cite{sy2020enhanced} gets implemented in the Linux kernel.
